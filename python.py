# python.py

import streamlit as st
import pandas as pd
from google import genai
from google.genai.errors import APIError
import os
import time # Th∆∞ vi·ªán h·ªØu √≠ch cho vi·ªác m√¥ ph·ªèng ƒë·ªô tr·ªÖ

# --- C·∫•u h√¨nh Trang Streamlit ---
st.set_page_config(
    page_title="App Ph√¢n T√≠ch B√°o C√°o T√†i Ch√≠nh",
    layout="wide"
)

st.title("·ª®ng d·ª•ng Ph√¢n T√≠ch B√°o C√°o T√†i Ch√≠nh üìä")

# --- H√†m t√≠nh to√°n ch√≠nh (S·ª≠ d·ª•ng Caching ƒë·ªÉ T·ªëi ∆∞u hi·ªáu su·∫•t) ---
@st.cache_data
def process_financial_data(df):
    """Th·ª±c hi·ªán c√°c ph√©p t√≠nh TƒÉng tr∆∞·ªüng v√† T·ª∑ tr·ªçng."""
    
    # ƒê·∫£m b·∫£o c√°c gi√° tr·ªã l√† s·ªë ƒë·ªÉ t√≠nh to√°n
    numeric_cols = ['NƒÉm tr∆∞·ªõc', 'NƒÉm sau']
    for col in numeric_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
    
    # 1. T√≠nh T·ªëc ƒë·ªô TƒÉng tr∆∞·ªüng
    # D√πng .replace(0, 1e-9) cho Series Pandas ƒë·ªÉ tr√°nh l·ªói chia cho 0
    df['T·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng (%)'] = (
        (df['NƒÉm sau'] - df['NƒÉm tr∆∞·ªõc']) / df['NƒÉm tr∆∞·ªõc'].replace(0, 1e-9)
    ) * 100

    # 2. T√≠nh T·ª∑ tr·ªçng theo T·ªïng T√†i s·∫£n
    # L·ªçc ch·ªâ ti√™u "T·ªîNG C·ªòNG T√ÄI S·∫¢N"
    tong_tai_san_row = df[df['Ch·ªâ ti√™u'].str.contains('T·ªîNG C·ªòNG T√ÄI S·∫¢N', case=False, na=False)]
    
    if tong_tai_san_row.empty:
        raise ValueError("Kh√¥ng t√¨m th·∫•y ch·ªâ ti√™u 'T·ªîNG C·ªòNG T√ÄI S·∫¢N'.")

    tong_tai_san_N_1 = tong_tai_san_row['NƒÉm tr∆∞·ªõc'].iloc[0]
    tong_tai_san_N = tong_tai_san_row['NƒÉm sau'].iloc[0]

    # ******************************* PH·∫¶N S·ª¨A L·ªñI B·∫ÆT ƒê·∫¶U *******************************
    # L·ªói x·∫£y ra khi d√πng .replace() tr√™n gi√° tr·ªã ƒë∆°n l·∫ª (numpy.int64).
    # S·ª≠ d·ª•ng ƒëi·ªÅu ki·ªán ternary ƒë·ªÉ x·ª≠ l√Ω gi√° tr·ªã 0 th·ªß c√¥ng cho m·∫´u s·ªë.
    
    divisor_N_1 = tong_tai_san_N_1 if tong_tai_san_N_1 != 0 else 1e-9
    divisor_N = tong_tai_san_N if tong_tai_san_N != 0 else 1e-9

    # T√≠nh t·ª∑ tr·ªçng v·ªõi m·∫´u s·ªë ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
    df['T·ª∑ tr·ªçng NƒÉm tr∆∞·ªõc (%)'] = (df['NƒÉm tr∆∞·ªõc'] / divisor_N_1) * 100
    df['T·ª∑ tr·ªçng NƒÉm sau (%)'] = (df['NƒÉm sau'] / divisor_N) * 100
    # ******************************* PH·∫¶N S·ª¨A L·ªñI K·∫æT TH√öC *******************************
    
    return df

# --- H√†m g·ªçi API Gemini cho Nh·∫≠n x√©t (Gi·ªØ nguy√™n) ---
def get_ai_analysis(data_for_ai, api_key):
    """G·ª≠i d·ªØ li·ªáu ph√¢n t√≠ch ƒë·∫øn Gemini API v√† nh·∫≠n nh·∫≠n x√©t."""
    try:
        client = genai.Client(api_key=api_key)
        model_name = 'gemini-2.5-flash' 

        prompt = f"""
        B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch t√†i ch√≠nh chuy√™n nghi·ªáp. D·ª±a tr√™n c√°c ch·ªâ s·ªë t√†i ch√≠nh sau, h√£y ƒë∆∞a ra m·ªôt nh·∫≠n x√©t kh√°ch quan, ng·∫Øn g·ªçn (kho·∫£ng 3-4 ƒëo·∫°n) v·ªÅ t√¨nh h√¨nh t√†i ch√≠nh c·ªßa doanh nghi·ªáp. ƒê√°nh gi√° t·∫≠p trung v√†o t·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng, thay ƒë·ªïi c∆° c·∫•u t√†i s·∫£n v√† kh·∫£ nƒÉng thanh to√°n hi·ªán h√†nh.
        
        D·ªØ li·ªáu th√¥ v√† ch·ªâ s·ªë:
        {data_for_ai}
        """

        response = client.models.generate_content(
            model=model_name,
            contents=prompt
        )
        return response.text

    except APIError as e:
        return f"L·ªói g·ªçi Gemini API: Vui l√≤ng ki·ªÉm tra Kh√≥a API ho·∫∑c gi·ªõi h·∫°n s·ª≠ d·ª•ng. Chi ti·∫øt l·ªói: {e}"
    except KeyError:
        return "L·ªói: Kh√¥ng t√¨m th·∫•y Kh√≥a API 'GEMINI_API_KEY'. Vui l√≤ng ki·ªÉm tra c·∫•u h√¨nh Secrets tr√™n Streamlit Cloud."
    except Exception as e:
        return f"ƒê√£ x·∫£y ra l·ªói kh√¥ng x√°c ƒë·ªãnh: {e}"

# --- H√†m chuy·ªÉn ƒë·ªïi ƒë·ªãnh d·∫°ng tin nh·∫Øn cho Gemini Chat (M·ªöI) ---
def to_gemini_format(st_messages):
    """Chuy·ªÉn ƒë·ªïi l·ªãch s·ª≠ chat c·ªßa Streamlit sang ƒë·ªãnh d·∫°ng API Gemini."""
    gemini_messages = []
    for message in st_messages:
        # Streamlit 'role' ('user', 'assistant') -> Gemini 'role' ('user', 'model')
        role = "user" if message["role"] == "user" else "model"
        
        # Ch·ªâ l·∫•y tin nh·∫Øn vƒÉn b·∫£n
        gemini_messages.append({
            "role": role,
            "parts": [{"text": message["content"]}]
        })
    return gemini_messages

# --- Ch·ª©c nƒÉng 1: T·∫£i File ---
uploaded_file = st.file_uploader(
    "1. T·∫£i file Excel B√°o c√°o T√†i ch√≠nh (Ch·ªâ ti√™u | NƒÉm tr∆∞·ªõc | NƒÉm sau)",
    type=['xlsx', 'xls']
)

# Kh·ªüi t·∫°o kh√≥a API, ∆∞u ti√™n l·∫•y t·ª´ st.secrets (d√πng cho Chatbot v√† Nh·∫≠n x√©t AI)
API_KEY = st.secrets.get("GEMINI_API_KEY")

if uploaded_file is not None:
    # ... (C√°c b∆∞·ªõc x·ª≠ l√Ω v√† hi·ªÉn th·ªã d·ªØ li·ªáu nh∆∞ c≈©) ...
    try:
        df_raw = pd.read_excel(uploaded_file)
        
        # Ti·ªÅn x·ª≠ l√Ω: ƒê·∫£m b·∫£o ch·ªâ c√≥ 3 c·ªôt quan tr·ªçng
        df_raw.columns = ['Ch·ªâ ti√™u', 'NƒÉm tr∆∞·ªõc', 'NƒÉm sau']
        
        # X·ª≠ l√Ω d·ªØ li·ªáu
        df_processed = process_financial_data(df_raw.copy())

        if df_processed is not None:
            
            # --- Ch·ª©c nƒÉng 2 & 3: Hi·ªÉn th·ªã K·∫øt qu·∫£ ---
            st.subheader("2. T·ªëc ƒë·ªô TƒÉng tr∆∞·ªüng & 3. T·ª∑ tr·ªçng C∆° c·∫•u T√†i s·∫£n")
            st.dataframe(df_processed.style.format({
                'NƒÉm tr∆∞·ªõc': '{:,.0f}',
                'NƒÉm sau': '{:,.0f}',
                'T·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng (%)': '{:.2f}%',
                'T·ª∑ tr·ªçng NƒÉm tr∆∞·ªõc (%)': '{:.2f}%',
                'T·ª∑ tr·ªçng NƒÉm sau (%)': '{:.2f}%'
            }), use_container_width=True)
            
            # --- Ch·ª©c nƒÉng 4: T√≠nh Ch·ªâ s·ªë T√†i ch√≠nh ---
            st.subheader("4. C√°c Ch·ªâ s·ªë T√†i ch√≠nh C∆° b·∫£n")
            
            try:
                # L·ªçc gi√° tr·ªã cho Ch·ªâ s·ªë Thanh to√°n Hi·ªán h√†nh (V√≠ d·ª•)
                
                # L·∫•y T√†i s·∫£n ng·∫Øn h·∫°n
                tsnh_n = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('T√ÄI S·∫¢N NG·∫ÆN H·∫†N', case=False, na=False)]['NƒÉm sau'].iloc[0]
                tsnh_n_1 = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('T√ÄI S·∫¢N NG·∫ÆN H·∫†N', case=False, na=False)]['NƒÉm tr∆∞·ªõc'].iloc[0]

                # L·∫•y N·ª£ ng·∫Øn h·∫°n (D√πng gi√° tr·ªã gi·∫£ ƒë·ªãnh ho·∫∑c l·ªçc t·ª´ file n·∫øu c√≥)
                no_ngan_han_N = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('N·ª¢ NG·∫ÆN H·∫†N', case=False, na=False)]['NƒÉm sau'].iloc[0]  
                no_ngan_han_N_1 = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('N·ª¢ NG·∫ÆN H·∫†N', case=False, na=False)]['NƒÉm tr∆∞·ªõc'].iloc[0]

                # T√≠nh to√°n, x·ª≠ l√Ω chia cho 0
                thanh_toan_hien_hanh_N = tsnh_n / no_ngan_han_N if no_ngan_han_N != 0 else float('inf')
                thanh_toan_hien_hanh_N_1 = tsnh_n_1 / no_ngan_han_N_1 if no_ngan_han_N_1 != 0 else float('inf')
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric(
                        label="Ch·ªâ s·ªë Thanh to√°n Hi·ªán h√†nh (NƒÉm tr∆∞·ªõc)",
                        value=f"{thanh_toan_hien_hanh_N_1:.2f} l·∫ßn" if thanh_toan_hien_hanh_N_1 != float('inf') else "‚àû"
                    )
                with col2:
                    delta_value = thanh_toan_hien_hanh_N - thanh_toan_hien_hanh_N_1 if thanh_toan_hien_hanh_N != float('inf') and thanh_toan_hien_hanh_N_1 != float('inf') else "N/A"
                    st.metric(
                        label="Ch·ªâ s·ªë Thanh to√°n Hi·ªán h√†nh (NƒÉm sau)",
                        value=f"{thanh_toan_hien_hanh_N:.2f} l·∫ßn" if thanh_toan_hien_hanh_N != float('inf') else "‚àû",
                        delta=f"{delta_value:.2f}" if isinstance(delta_value, float) else None
                    )
                    
            except IndexError:
                 st.warning("Thi·∫øu ch·ªâ ti√™u 'T√ÄI S·∫¢N NG·∫ÆN H·∫†N' ho·∫∑c 'N·ª¢ NG·∫ÆN H·∫†N' ƒë·ªÉ t√≠nh ch·ªâ s·ªë.")
                 thanh_toan_hien_hanh_N = "N/A" # D√πng ƒë·ªÉ tr√°nh l·ªói ·ªü Ch·ª©c nƒÉng 5
                 thanh_toan_hien_hanh_N_1 = "N/A"
            except ZeroDivisionError:
                 st.warning("L·ªói: N·ª£ Ng·∫Øn H·∫°n b·∫±ng 0. Ch·ªâ s·ªë thanh to√°n hi·ªán h√†nh r·∫•t l·ªõn (v√¥ c√πng).")
                 thanh_toan_hien_hanh_N = "Inf"
                 thanh_toan_hien_hanh_N_1 = "Inf"
                
            # --- Ch·ª©c nƒÉng 5: Nh·∫≠n x√©t AI ---
            st.subheader("5. Nh·∫≠n x√©t T√¨nh h√¨nh T√†i ch√≠nh (AI)")
            
            # Chu·∫©n b·ªã d·ªØ li·ªáu ƒë·ªÉ g·ª≠i cho AI
            data_for_ai = pd.DataFrame({
                'Ch·ªâ ti√™u': [
                    'To√†n b·ªô B·∫£ng ph√¢n t√≠ch (d·ªØ li·ªáu th√¥)', 
                    'TƒÉng tr∆∞·ªüng T√†i s·∫£n ng·∫Øn h·∫°n (%)', 
                    'Thanh to√°n hi·ªán h√†nh (N-1)', 
                    'Thanh to√°n hi·ªán h√†nh (N)'
                ],
                'Gi√° tr·ªã': [
                    df_processed.to_markdown(index=False),
                    f"{df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('T√ÄI S·∫¢N NG·∫ÆN H·∫†N', case=False, na=False)]['T·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng (%)'].iloc[0]:.2f}%" if not df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('T√ÄI S·∫¢N NG·∫ÆN H·∫†N', case=False, na=False)].empty else "N/A", 
                    f"{thanh_toan_hien_hanh_N_1}", 
                    f"{thanh_toan_hien_hanh_N}"
                ]
            }).to_markdown(index=False) 

            if st.button("Y√™u c·∫ßu AI Ph√¢n t√≠ch"):
                if API_KEY:
                    with st.spinner('ƒêang g·ª≠i d·ªØ li·ªáu v√† ch·ªù Gemini ph√¢n t√≠ch...'):
                        ai_result = get_ai_analysis(data_for_ai, API_KEY)
                    st.markdown("**K·∫øt qu·∫£ Ph√¢n t√≠ch t·ª´ Gemini AI:**")
                    st.info(ai_result)
                else:
                    st.error("L·ªói: Kh√¥ng t√¨m th·∫•y Kh√≥a API. Vui l√≤ng c·∫•u h√¨nh Kh√≥a 'GEMINI_API_KEY' trong Streamlit Secrets.")

    except ValueError as ve:
        st.error(f"L·ªói c·∫•u tr√∫c d·ªØ li·ªáu: {ve}")
    except Exception as e:
        st.error(f"C√≥ l·ªói x·∫£y ra khi ƒë·ªçc ho·∫∑c x·ª≠ l√Ω file: {e}. Vui l√≤ng ki·ªÉm tra ƒë·ªãnh d·∫°ng file.")

else:
    st.info("Vui l√≤ng t·∫£i l√™n file Excel ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch.")

# -----------------------------------------------------------
# --------------- PH·∫¶N T√çCH H·ª¢P CHATBOT GEMINI M·ªöI ---------------
# -----------------------------------------------------------

st.divider()

# Kh·ªüi t·∫°o l·ªãch s·ª≠ chat trong session_state
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.messages.append({"role": "assistant", "content": "Ch√†o b·∫°n! T√¥i l√† Gemini. B·∫°n c√≥ th·ªÉ h·ªèi t√¥i th√™m v·ªÅ d·ªØ li·ªáu ƒë√£ t·∫£i ho·∫∑c c√°c kh√°i ni·ªám t√†i ch√≠nh kh√°c."})

st.subheader("6. Chat H·ªèi ƒë√°p v·ªõi Gemini üí¨")

# 1. Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 2. X·ª≠ l√Ω khung nh·∫≠p li·ªáu
if prompt := st.chat_input("H·ªèi Gemini v·ªÅ b√°o c√°o t√†i ch√≠nh ho·∫∑c b·∫•t c·ª© ƒëi·ªÅu g√¨..."):
    
    if not API_KEY:
        st.error("L·ªói: Kh√¥ng t√¨m th·∫•y Kh√≥a API 'GEMINI_API_KEY'. Kh√¥ng th·ªÉ chat.")
    else:
        # Th√™m tin nh·∫Øn ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠ v√† hi·ªÉn th·ªã
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Chu·∫©n b·ªã ng·ªØ c·∫£nh (context)
        # N·∫øu c√≥ d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω, th√™m n√≥ v√†o ng·ªØ c·∫£nh ƒë·ªÉ Gemini tr·∫£ l·ªùi t·ªët h∆°n
        context_data = ""
        if 'df_processed' in locals() and df_processed is not None:
             context_data = "\n\nD·ªØ li·ªáu B√°o c√°o T√†i ch√≠nh ƒë√£ x·ª≠ l√Ω (T·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng v√† T·ª∑ tr·ªçng): \n" + df_processed.to_markdown(index=False)
        
        # 3. B·∫Øt ƒë·∫ßu tr·∫£ l·ªùi
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            
            try:
                client = genai.Client(api_key=API_KEY)
                model_name = "gemini-2.5-flash"
                
                # L·∫•y l·ªãch s·ª≠ tin nh·∫Øn Streamlit (tr·ª´ tin nh·∫Øn cu·ªëi c√πng v·ª´a th√™m)
                st_history = st.session_state.messages[:-1]
                
                # Chuy·ªÉn ƒë·ªïi l·ªãch s·ª≠ sang ƒë·ªãnh d·∫°ng Gemini
                gemini_history = to_gemini_format(st_history)

                # B·ªï sung d·ªØ li·ªáu ph√¢n t√≠ch v√†o tin nh·∫Øn ƒë·∫ßu ti√™n c·ªßa phi√™n chat
                # ƒë·ªÉ cung c·∫•p ng·ªØ c·∫£nh chuy√™n bi·ªát khi c·∫ßn.
                if context_data and not any("D·ªØ li·ªáu B√°o c√°o T√†i ch√≠nh" in m["parts"][0]["text"] for m in gemini_history if m["role"] == "user"):
                    # Th√™m d·ªØ li·ªáu v√†o tin nh·∫Øn PROMPT
                    full_prompt = prompt + context_data
                else:
                    full_prompt = prompt

                # G·ªçi API Gemini v·ªõi ch·∫ø ƒë·ªô Streaming
                response_stream = client.models.generate_content_stream(
                    model=model_name,
                    contents=gemini_history + [{"role": "user", "parts": [{"text": full_prompt}]}]
                )

                # Hi·ªÉn th·ªã ph·∫£n h·ªìi streaming
                for chunk in response_stream:
                    if chunk.text:
                        full_response += chunk.text
                        message_placeholder.markdown(full_response + "‚ñå")
                        
                message_placeholder.markdown(full_response) # Hi·ªÉn th·ªã ph·∫£n h·ªìi cu·ªëi c√πng
                
            except APIError as e:
                error_message = f"L·ªói API Gemini: {e}"
                message_placeholder.markdown(error_message)
                full_response = error_message
            except Exception as e:
                error_message = f"ƒê√£ x·∫£y ra l·ªói kh√¥ng x√°c ƒë·ªãnh: {e}"
                message_placeholder.markdown(error_message)
                full_response = error_message

        # 4. Th√™m ph·∫£n h·ªìi c·ªßa tr·ª£ l√Ω v√†o l·ªãch s·ª≠ chat c·ªßa Streamlit
        st.session_state.messages.append({"role": "assistant", "content": full_response})
